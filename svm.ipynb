{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796a54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0880229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b24fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e5bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_classifier():\n",
    "\n",
    "\n",
    "  # initializing  hyperparameters\n",
    "  def __init__(self, learning_rate, no_of_iterations, lambda_parameter):\n",
    "\n",
    "    self.learning_rate = learning_rate\n",
    "    self.no_of_iterations = no_of_iterations\n",
    "    self.lambda_parameter = lambda_parameter\n",
    "\n",
    "\n",
    "  \n",
    "  # fitting the dataset \n",
    "  def fit(self, X, Y):\n",
    "\n",
    "    # m  --> number of Data points\n",
    "    # n  --> number of input features \n",
    "    self.m, self.n = X.shape\n",
    "\n",
    "    # initializing the weight value and bias value\n",
    "\n",
    "    self.w = np.zeros(self.n)\n",
    "\n",
    "    self.b = 0\n",
    "\n",
    "    self.X = X\n",
    "\n",
    "    self.Y = Y\n",
    "\n",
    "    # implementing Gradient Descent algorithm for Optimization\n",
    "\n",
    "    for i in range(self.no_of_iterations):\n",
    "      self.update_weights()\n",
    "\n",
    "\n",
    "\n",
    "  # function for updating the weight and bias value\n",
    "  def update_weights(self):\n",
    "\n",
    "    # label encoding\n",
    "    y_label = np.where(self.Y <= 0, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # gradients update ( dw, db)\n",
    "    for index, x_i in enumerate(self.X):\n",
    "      temp1=x_i.reshape([1,self.n])\n",
    "      temp2=self.w.reshape([self.n,1])\n",
    "      temp3=temp1 @ temp2\n",
    "      condition = y_label[index] * temp3 >= 1\n",
    "      print(condition)\n",
    "\n",
    "      if (condition == True):\n",
    "\n",
    "        dw = 2 * self.lambda_parameter * self.w\n",
    "        db = 0\n",
    "\n",
    "      else:\n",
    "\n",
    "        dw = 2 * self.lambda_parameter * self.w - np.dot(x_i, y_label[index])\n",
    "        db = y_label[index]\n",
    "\n",
    "\n",
    "      self.w = self.w - self.learning_rate * dw\n",
    "\n",
    "      self.b = self.b - self.learning_rate * db\n",
    "      \n",
    "      print(self.w.shape)\n",
    "      print(self.b.shape)\n",
    "\n",
    "\n",
    "\n",
    "  # predict the label for a given input value\n",
    "  def predict(self, X):\n",
    "    #output = self.w.dot(X) - self.b\n",
    "    self.m, self.n = X.shape\n",
    "\n",
    "    temp4=X.reshape([self.m,self.n])\n",
    "    temp5=self.w.reshape(self.n,1)\n",
    "    print(X.shape)\n",
    "    print(self.w.shape)\n",
    "    temp6=temp4 @ temp5\n",
    "    print(temp6.shape)\n",
    "    #predicted_labels = np.sign(output)\n",
    "    predicted_labels = np.sign(temp6 + self.b)\n",
    "\n",
    "\n",
    "    y_hat = np.where(predicted_labels <= -1, 0, 1)\n",
    "\n",
    "    return y_hat  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde19331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 2810: expected 2 fields, saw 5\\nSkipping line 4641: expected 2 fields, saw 5\\nSkipping line 7171: expected 2 fields, saw 5\\nSkipping line 11220: expected 2 fields, saw 5\\nSkipping line 13809: expected 2 fields, saw 5\\nSkipping line 14132: expected 2 fields, saw 5\\nSkipping line 14293: expected 2 fields, saw 5\\nSkipping line 14865: expected 2 fields, saw 5\\nSkipping line 17419: expected 2 fields, saw 5\\nSkipping line 22801: expected 2 fields, saw 5\\nSkipping line 25001: expected 2 fields, saw 5\\nSkipping line 26603: expected 2 fields, saw 5\\nSkipping line 26742: expected 2 fields, saw 5\\nSkipping line 29702: expected 2 fields, saw 5\\nSkipping line 32767: expected 2 fields, saw 5\\nSkipping line 32878: expected 2 fields, saw 5\\nSkipping line 35643: expected 2 fields, saw 5\\nSkipping line 36550: expected 2 fields, saw 5\\nSkipping line 38732: expected 2 fields, saw 5\\nSkipping line 40567: expected 2 fields, saw 5\\nSkipping line 40576: expected 2 fields, saw 5\\nSkipping line 41864: expected 2 fields, saw 5\\nSkipping line 46861: expected 2 fields, saw 5\\nSkipping line 47939: expected 2 fields, saw 5\\nSkipping line 48628: expected 2 fields, saw 5\\nSkipping line 48908: expected 2 fields, saw 5\\nSkipping line 57582: expected 2 fields, saw 5\\nSkipping line 58782: expected 2 fields, saw 5\\nSkipping line 58984: expected 2 fields, saw 5\\nSkipping line 61518: expected 2 fields, saw 5\\nSkipping line 63451: expected 2 fields, saw 5\\nSkipping line 68141: expected 2 fields, saw 5\\nSkipping line 72083: expected 2 fields, saw 5\\nSkipping line 74027: expected 2 fields, saw 5\\nSkipping line 77811: expected 2 fields, saw 5\\nSkipping line 83958: expected 2 fields, saw 5\\nSkipping line 85295: expected 2 fields, saw 5\\nSkipping line 88665: expected 2 fields, saw 5\\nSkipping line 89198: expected 2 fields, saw 5\\nSkipping line 92499: expected 2 fields, saw 5\\nSkipping line 92751: expected 2 fields, saw 5\\nSkipping line 93689: expected 2 fields, saw 5\\nSkipping line 94776: expected 2 fields, saw 5\\nSkipping line 97334: expected 2 fields, saw 5\\nSkipping line 102316: expected 2 fields, saw 5\\nSkipping line 103421: expected 2 fields, saw 5\\nSkipping line 106872: expected 2 fields, saw 5\\nSkipping line 109363: expected 2 fields, saw 5\\nSkipping line 110117: expected 2 fields, saw 5\\nSkipping line 110465: expected 2 fields, saw 5\\nSkipping line 113843: expected 2 fields, saw 5\\nSkipping line 115634: expected 2 fields, saw 5\\nSkipping line 121518: expected 2 fields, saw 5\\nSkipping line 123692: expected 2 fields, saw 5\\nSkipping line 124708: expected 2 fields, saw 5\\nSkipping line 129608: expected 2 fields, saw 5\\nSkipping line 133176: expected 2 fields, saw 5\\nSkipping line 135532: expected 2 fields, saw 5\\nSkipping line 138042: expected 2 fields, saw 5\\nSkipping line 139485: expected 2 fields, saw 5\\nSkipping line 140401: expected 2 fields, saw 5\\nSkipping line 144093: expected 2 fields, saw 5\\nSkipping line 149850: expected 2 fields, saw 5\\nSkipping line 151831: expected 2 fields, saw 5\\nSkipping line 158014: expected 2 fields, saw 5\\nSkipping line 162047: expected 2 fields, saw 5\\nSkipping line 164515: expected 2 fields, saw 5\\nSkipping line 170313: expected 2 fields, saw 5\\nSkipping line 171325: expected 2 fields, saw 5\\nSkipping line 171424: expected 2 fields, saw 5\\nSkipping line 175920: expected 2 fields, saw 5\\nSkipping line 176210: expected 2 fields, saw 5\\nSkipping line 183603: expected 2 fields, saw 5\\nSkipping line 190264: expected 2 fields, saw 5\\nSkipping line 191683: expected 2 fields, saw 5\\nSkipping line 191988: expected 2 fields, saw 5\\nSkipping line 195450: expected 2 fields, saw 5\\nSkipping line 195754: expected 2 fields, saw 5\\nSkipping line 197124: expected 2 fields, saw 5\\nSkipping line 199263: expected 2 fields, saw 5\\nSkipping line 202603: expected 2 fields, saw 5\\nSkipping line 209960: expected 2 fields, saw 5\\nSkipping line 213218: expected 2 fields, saw 5\\nSkipping line 217060: expected 2 fields, saw 5\\nSkipping line 220121: expected 2 fields, saw 5\\nSkipping line 223518: expected 2 fields, saw 5\\nSkipping line 226293: expected 2 fields, saw 5\\nSkipping line 227035: expected 2 fields, saw 7\\nSkipping line 227341: expected 2 fields, saw 5\\nSkipping line 227808: expected 2 fields, saw 5\\nSkipping line 228516: expected 2 fields, saw 5\\nSkipping line 228733: expected 2 fields, saw 5\\nSkipping line 232043: expected 2 fields, saw 5\\nSkipping line 232426: expected 2 fields, saw 5\\nSkipping line 234490: expected 2 fields, saw 5\\nSkipping line 239626: expected 2 fields, saw 5\\nSkipping line 240461: expected 2 fields, saw 5\\nSkipping line 244518: expected 2 fields, saw 5\\nSkipping line 245395: expected 2 fields, saw 5\\nSkipping line 246168: expected 2 fields, saw 5\\nSkipping line 246655: expected 2 fields, saw 5\\nSkipping line 246752: expected 2 fields, saw 5\\nSkipping line 247189: expected 2 fields, saw 5\\nSkipping line 250276: expected 2 fields, saw 5\\nSkipping line 255327: expected 2 fields, saw 5\\nSkipping line 257094: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 264626: expected 2 fields, saw 5\\nSkipping line 265028: expected 2 fields, saw 5\\nSkipping line 269150: expected 2 fields, saw 5\\nSkipping line 271360: expected 2 fields, saw 5\\nSkipping line 273975: expected 2 fields, saw 5\\nSkipping line 274742: expected 2 fields, saw 5\\nSkipping line 276227: expected 2 fields, saw 5\\nSkipping line 279807: expected 2 fields, saw 5\\nSkipping line 283425: expected 2 fields, saw 5\\nSkipping line 287468: expected 2 fields, saw 5\\nSkipping line 292995: expected 2 fields, saw 5\\nSkipping line 293496: expected 2 fields, saw 5\\nSkipping line 293735: expected 2 fields, saw 5\\nSkipping line 295060: expected 2 fields, saw 5\\nSkipping line 296643: expected 2 fields, saw 5\\nSkipping line 296848: expected 2 fields, saw 5\\nSkipping line 308926: expected 2 fields, saw 5\\nSkipping line 310360: expected 2 fields, saw 5\\nSkipping line 317004: expected 2 fields, saw 5\\nSkipping line 318207: expected 2 fields, saw 5\\nSkipping line 331783: expected 2 fields, saw 5\\nSkipping line 333864: expected 2 fields, saw 5\\nSkipping line 335958: expected 2 fields, saw 5\\nSkipping line 336290: expected 2 fields, saw 5\\nSkipping line 343526: expected 2 fields, saw 5\\nSkipping line 343857: expected 2 fields, saw 5\\nSkipping line 344059: expected 2 fields, saw 5\\nSkipping line 348691: expected 2 fields, saw 5\\nSkipping line 353446: expected 2 fields, saw 5\\nSkipping line 357073: expected 2 fields, saw 5\\nSkipping line 359753: expected 2 fields, saw 5\\nSkipping line 359974: expected 2 fields, saw 5\\nSkipping line 366534: expected 2 fields, saw 5\\nSkipping line 369514: expected 2 fields, saw 5\\nSkipping line 377759: expected 2 fields, saw 5\\nSkipping line 379327: expected 2 fields, saw 5\\nSkipping line 380769: expected 2 fields, saw 5\\nSkipping line 381073: expected 2 fields, saw 5\\nSkipping line 381489: expected 2 fields, saw 5\\nSkipping line 386304: expected 2 fields, saw 5\\nSkipping line 387635: expected 2 fields, saw 5\\nSkipping line 389613: expected 2 fields, saw 5\\nSkipping line 392604: expected 2 fields, saw 5\\nSkipping line 393184: expected 2 fields, saw 5\\nSkipping line 395530: expected 2 fields, saw 5\\nSkipping line 396939: expected 2 fields, saw 5\\nSkipping line 397385: expected 2 fields, saw 5\\nSkipping line 397509: expected 2 fields, saw 5\\nSkipping line 402902: expected 2 fields, saw 5\\nSkipping line 405187: expected 2 fields, saw 5\\nSkipping line 408412: expected 2 fields, saw 5\\nSkipping line 419423: expected 2 fields, saw 5\\nSkipping line 420962: expected 2 fields, saw 5\\nSkipping line 425965: expected 2 fields, saw 5\\nSkipping line 427496: expected 2 fields, saw 5\\nSkipping line 438881: expected 2 fields, saw 5\\nSkipping line 439776: expected 2 fields, saw 5\\nSkipping line 440345: expected 2 fields, saw 5\\nSkipping line 445507: expected 2 fields, saw 5\\nSkipping line 445548: expected 2 fields, saw 5\\nSkipping line 447184: expected 2 fields, saw 5\\nSkipping line 448603: expected 2 fields, saw 5\\nSkipping line 451732: expected 2 fields, saw 5\\nSkipping line 458249: expected 2 fields, saw 5\\nSkipping line 460274: expected 2 fields, saw 5\\nSkipping line 467630: expected 2 fields, saw 5\\nSkipping line 473961: expected 2 fields, saw 5\\nSkipping line 476281: expected 2 fields, saw 5\\nSkipping line 478010: expected 2 fields, saw 5\\nSkipping line 478322: expected 2 fields, saw 5\\nSkipping line 479999: expected 2 fields, saw 5\\nSkipping line 480898: expected 2 fields, saw 5\\nSkipping line 481688: expected 2 fields, saw 5\\nSkipping line 485193: expected 2 fields, saw 5\\nSkipping line 485519: expected 2 fields, saw 5\\nSkipping line 486000: expected 2 fields, saw 5\\nSkipping line 489063: expected 2 fields, saw 5\\nSkipping line 494525: expected 2 fields, saw 5\\nSkipping line 495009: expected 2 fields, saw 5\\nSkipping line 501954: expected 2 fields, saw 5\\nSkipping line 508035: expected 2 fields, saw 5\\nSkipping line 508828: expected 2 fields, saw 5\\nSkipping line 509833: expected 2 fields, saw 5\\nSkipping line 510410: expected 2 fields, saw 5\\nSkipping line 518229: expected 2 fields, saw 5\\nSkipping line 520302: expected 2 fields, saw 5\\nSkipping line 520340: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 525174: expected 2 fields, saw 5\\nSkipping line 526251: expected 2 fields, saw 5\\nSkipping line 529611: expected 2 fields, saw 5\\nSkipping line 531398: expected 2 fields, saw 5\\nSkipping line 534146: expected 2 fields, saw 5\\nSkipping line 544954: expected 2 fields, saw 5\\nSkipping line 553002: expected 2 fields, saw 5\\nSkipping line 553883: expected 2 fields, saw 5\\nSkipping line 553887: expected 2 fields, saw 5\\nSkipping line 553915: expected 2 fields, saw 5\\nSkipping line 554172: expected 2 fields, saw 5\\nSkipping line 563534: expected 2 fields, saw 5\\nSkipping line 565191: expected 2 fields, saw 5\\nSkipping line 574108: expected 2 fields, saw 5\\nSkipping line 574412: expected 2 fields, saw 5\\nSkipping line 575985: expected 2 fields, saw 5\\nSkipping line 580091: expected 2 fields, saw 5\\nSkipping line 582682: expected 2 fields, saw 5\\nSkipping line 585885: expected 2 fields, saw 5\\nSkipping line 590171: expected 2 fields, saw 5\\nSkipping line 591924: expected 2 fields, saw 5\\nSkipping line 592515: expected 2 fields, saw 5\\nSkipping line 593888: expected 2 fields, saw 5\\nSkipping line 596245: expected 2 fields, saw 5\\nSkipping line 607344: expected 2 fields, saw 5\\nSkipping line 607633: expected 2 fields, saw 5\\nSkipping line 610939: expected 2 fields, saw 5\\nSkipping line 613638: expected 2 fields, saw 5\\nSkipping line 615643: expected 2 fields, saw 5\\nSkipping line 615901: expected 2 fields, saw 5\\nSkipping line 617389: expected 2 fields, saw 5\\nSkipping line 634641: expected 2 fields, saw 5\\nSkipping line 635755: expected 2 fields, saw 5\\nSkipping line 646243: expected 2 fields, saw 5\\nSkipping line 647165: expected 2 fields, saw 5\\nSkipping line 648610: expected 2 fields, saw 5\\nSkipping line 648772: expected 2 fields, saw 5\\nSkipping line 651833: expected 2 fields, saw 5\\nSkipping line 653663: expected 2 fields, saw 5\\nSkipping line 656233: expected 2 fields, saw 5\\nSkipping line 656694: expected 2 fields, saw 5\\nSkipping line 659783: expected 2 fields, saw 5\\nSkipping line 660478: expected 2 fields, saw 5\\nSkipping line 661133: expected 2 fields, saw 5\\nSkipping line 661736: expected 2 fields, saw 5\\nSkipping line 669827: expected 2 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    586503\n",
       "1     83137\n",
       "Name: strength, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\varsh\\OneDrive\\Documents\\INSE 6180\\data.csv',error_bad_lines=False)\n",
    "dummy = data.strength\n",
    "d = dummy.replace(1,0)\n",
    "y = d.replace(2,1)\n",
    "data['strength'].value_counts()\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ee586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "669635    0\n",
      "669636    0\n",
      "669637    0\n",
      "669638    0\n",
      "669639    0\n",
      "Name: strength, Length: 669640, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "features=data['password']\n",
    "target=y\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1968db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_divide_char(inputs):\n",
    "    character=[]\n",
    "    for i in inputs:\n",
    "        character.append(i)\n",
    "    return character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48787b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer(tokenizer=word_divide_char)\n",
    "X=vectorizer.fit_transform(features)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226216ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 41)\t0.5913033374804587\n",
      "  (0, 39)\t0.5668990475107434\n",
      "  (0, 60)\t0.221689578545907\n",
      "  (0, 59)\t0.2856314454344638\n",
      "  (0, 81)\t0.3359256904431869\n",
      "  (0, 66)\t0.2922467650108519\n",
      "  (1, 38)\t0.6177740147525559\n",
      "  (1, 37)\t0.5602425115534002\n",
      "  (1, 70)\t0.25649928309246306\n",
      "  (1, 69)\t0.26770311076536885\n",
      "  (1, 64)\t0.2519907735724838\n",
      "  (1, 66)\t0.321756751659985\n",
      "  (2, 73)\t0.2894510846576453\n",
      "  (2, 80)\t0.33760964730400084\n",
      "  (2, 35)\t0.2261102829164477\n",
      "  (2, 74)\t0.29731144435173845\n",
      "  (2, 77)\t0.39246472118131376\n",
      "  (2, 64)\t0.527990462866844\n",
      "  (2, 41)\t0.3410120562248123\n",
      "  (2, 66)\t0.33708475479286015\n",
      "  (3, 36)\t0.30323421767408737\n",
      "  (3, 62)\t0.4010456064880801\n",
      "  (3, 68)\t0.3498334199966546\n",
      "  (3, 80)\t0.3906222854709323\n",
      "  (3, 35)\t0.2616149040367047\n",
      "  :\t:\n",
      "  (669636, 34)\t0.2910319203906559\n",
      "  (669636, 42)\t0.3278337368686998\n",
      "  (669636, 58)\t0.33655295850307515\n",
      "  (669636, 56)\t0.21511034432170514\n",
      "  (669636, 36)\t0.25833498206981703\n",
      "  (669636, 68)\t0.29803434116195854\n",
      "  (669636, 73)\t0.28531352718392095\n",
      "  (669636, 35)\t0.22287815030214636\n",
      "  (669636, 74)\t0.29306152699504145\n",
      "  (669636, 38)\t0.3189761890316904\n",
      "  (669636, 70)\t0.26487732360502647\n",
      "  (669636, 39)\t0.3222643847680912\n",
      "  (669637, 56)\t0.4605526599777346\n",
      "  (669637, 36)\t0.553096893283851\n",
      "  (669637, 68)\t0.3190467409172422\n",
      "  (669637, 73)\t0.3054290677803674\n",
      "  (669637, 69)\t0.29593753060621225\n",
      "  (669637, 60)\t0.26981734333745055\n",
      "  (669637, 66)\t0.355692163120169\n",
      "  (669638, 79)\t0.6437666648277904\n",
      "  (669638, 71)\t0.2791167336840736\n",
      "  (669638, 78)\t0.29382027345916834\n",
      "  (669638, 61)\t0.30978766772321525\n",
      "  (669638, 62)\t0.26929737468158327\n",
      "  (669638, 38)\t0.50283049037885\n",
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         1\n",
      "         ..\n",
      "669635    1\n",
      "669636    1\n",
      "669637    1\n",
      "669638    1\n",
      "669639    1\n",
      "Name: strength, Length: 669639, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features=X\n",
    "target=data['strength']\n",
    "print(features)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(669639, 153) (448658, 153) (220981, 153)\n",
      "(448658, 153)\n",
      "(220981, 153)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.33, random_state = 42)\n",
    "print(features.shape, X_train.shape, X_test.shape)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaling=StandardScaler(with_mean=False).fit(X_train)\n",
    "X_train= scaling.transform(X_train)\n",
    "X_test= scaling.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f022a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVM_classifier(learning_rate=0.01, no_of_iterations=10, lambda_parameter=0.01)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = classifier.predict(X_train)\n",
    "training_acc = accuracy_score(Y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy = ', training_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = classifier.predict(X_test)\n",
    "test_acc = accuracy_score(Y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a55c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy = ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a842d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(669639, 153) (448658, 153) (220981, 153)\n",
      "  (0, 40)\t0.6345897887638462\n",
      "  (0, 76)\t0.29748563902650127\n",
      "  (0, 72)\t0.3818914631780121\n",
      "  (0, 63)\t0.3258311396521368\n",
      "  (0, 56)\t0.20400694512138245\n",
      "  (0, 37)\t0.2724067248491352\n",
      "  (0, 64)\t0.24673248967857686\n",
      "  (0, 66)\t0.3137715826889502\n",
      "  (1, 75)\t0.4023407532405992\n",
      "  (1, 63)\t0.45760512193036995\n",
      "  (1, 74)\t0.38772256466175864\n",
      "  (1, 38)\t0.42129425576176355\n",
      "  (1, 64)\t0.3465170675340897\n",
      "  (1, 41)\t0.44368471843551455\n",
      "  (2, 43)\t0.23481956802323528\n",
      "  (2, 42)\t0.2497405982728872\n",
      "  (2, 76)\t0.24032347675051194\n",
      "  (2, 72)\t0.30851063759788433\n",
      "  (2, 74)\t0.22302470853801262\n",
      "  (2, 38)\t0.24233572446827853\n",
      "  (2, 37)\t0.6601905028443972\n",
      "  (2, 64)\t0.19932259567522548\n",
      "  (2, 41)\t0.25521510489897614\n",
      "  (2, 39)\t0.2454603779749716\n",
      "  (2, 60)\t0.19470947280477718\n",
      "  :\t:\n",
      "  (448655, 43)\t0.29848012426209986\n",
      "  (448655, 58)\t0.32741821036326546\n",
      "  (448655, 75)\t0.29417587939246415\n",
      "  (448655, 77)\t0.37515292290595964\n",
      "  (448655, 37)\t0.2797236263634206\n",
      "  (448655, 69)\t0.5353552221582282\n",
      "  (448655, 64)\t0.2533597758748057\n",
      "  (448655, 41)\t0.32440497555243614\n",
      "  (448655, 60)\t0.2474960163116696\n",
      "  (448656, 42)\t0.6330121198150152\n",
      "  (448656, 72)\t0.7819752737115159\n",
      "  (448657, 71)\t0.24915798392168179\n",
      "  (448657, 76)\t0.22233035152465844\n",
      "  (448657, 75)\t0.21410582585731844\n",
      "  (448657, 72)\t0.28541230941595064\n",
      "  (448657, 56)\t0.15246764842409108\n",
      "  (448657, 68)\t0.2081622731066116\n",
      "  (448657, 73)\t0.40623194753739517\n",
      "  (448657, 77)\t0.2730421900920304\n",
      "  (448657, 38)\t0.22419194136388246\n",
      "  (448657, 69)\t0.19481996995120035\n",
      "  (448657, 39)\t0.22708265067755068\n",
      "  (448657, 59)\t0.4603963722595412\n",
      "  (448657, 81)\t0.2680155446539567\n",
      "  (448657, 66)\t0.23450189564097967\n",
      "  (0, 43)\t0.3019359172637921\n",
      "  (0, 58)\t0.33120904756824604\n",
      "  (0, 76)\t0.3090129583472764\n",
      "  (0, 73)\t0.5646144803121204\n",
      "  (0, 70)\t0.25964960014102156\n",
      "  (0, 60)\t0.5007230339972567\n",
      "  (0, 59)\t0.3199483202105582\n",
      "  (1, 67)\t0.285358697469221\n",
      "  (1, 36)\t0.23888722681240462\n",
      "  (1, 62)\t0.6401343191850509\n",
      "  (1, 70)\t0.48997198296064626\n",
      "  (1, 41)\t0.3096281669047497\n",
      "  (1, 60)\t0.23622244916654705\n",
      "  (1, 59)\t0.30187936513931085\n",
      "  (2, 79)\t0.2926462450962733\n",
      "  (2, 76)\t0.22717033743009857\n",
      "  (2, 72)\t0.29162554816333375\n",
      "  (2, 57)\t0.2593257096855735\n",
      "  (2, 56)\t0.15578676911250666\n",
      "  (2, 68)\t0.42538765847811466\n",
      "  (2, 73)\t0.20753767527489617\n",
      "  (2, 74)\t0.42163669549792987\n",
      "  (2, 37)\t0.20801920995148707\n",
      "  (2, 70)\t0.19088095073132047\n",
      "  (2, 60)\t0.18405283260701502\n",
      "  :\t:\n",
      "  (220977, 35)\t0.20682126278619511\n",
      "  (220978, 34)\t0.4628608954064914\n",
      "  (220978, 76)\t0.2531295879585895\n",
      "  (220978, 72)\t0.3249502363727261\n",
      "  (220978, 67)\t0.2477443396902559\n",
      "  (220978, 36)\t0.2073984735420903\n",
      "  (220978, 73)\t0.23125345862719845\n",
      "  (220978, 35)\t0.17723413307536662\n",
      "  (220978, 74)\t0.4698180414177234\n",
      "  (220978, 70)\t0.42538666759369964\n",
      "  (220978, 60)\t0.20508495170396393\n",
      "  (220979, 58)\t0.37609989493809254\n",
      "  (220979, 75)\t0.3379149779423506\n",
      "  (220979, 63)\t0.3843300074326254\n",
      "  (220979, 56)\t0.4812676334037058\n",
      "  (220979, 68)\t0.3285344975718971\n",
      "  (220979, 35)\t0.2456869931290177\n",
      "  (220979, 60)\t0.28429458956831066\n",
      "  (220979, 66)\t0.37010530925846097\n",
      "  (220980, 56)\t0.21300872517859842\n",
      "  (220980, 62)\t0.3409802903027805\n",
      "  (220980, 73)\t0.28376822941176566\n",
      "  (220980, 77)\t0.7629207826397635\n",
      "  (220980, 38)\t0.3132129348017809\n",
      "  (220980, 59)\t0.32160410862728545\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.33, random_state = 42)\n",
    "print(features.shape, X_train.shape, X_test.shape)\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaling=MaxAbsScaler().fit(X_train)\n",
    "X_train= scaling.transform(X_train)\n",
    "X_test= scaling.transform(X_test)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853484a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8158129354653211\n",
      "Test acc: 0.8168575578895924\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Train acc: {}\".format(accuracy_score(Y_train, train_pred)))\n",
    "print(\"Test acc: {}\".format(accuracy_score(Y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317b23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.11      0.19     29558\n",
      "           1       0.82      0.97      0.89    163934\n",
      "           2       0.82      0.69      0.75     27489\n",
      "\n",
      "    accuracy                           0.82    220981\n",
      "   macro avg       0.77      0.59      0.61    220981\n",
      "weighted avg       0.80      0.82      0.78    220981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c77c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48efdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423ec81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
